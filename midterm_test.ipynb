{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/02 12:35:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('test_data')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro ficheiro com IDs 1 - 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = (spark.read\n",
    "    .option(\"sep\", \";\")\n",
    "    .option(\"header\", \"True\")\n",
    "    .option(\"inferSchema\", \"True\")\n",
    "    .csv('/home/mcanudo/Documents/NOVA/ABD/exame/Midterm_Test_Data_24.csv')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.withColumn(\"Date\", to_date(df1[\"Date\"], \"dd/MM/yyyy\").cast(DateType()))\n",
    "df1 = df1.withColumn(\"Date1\", to_date(df1[\"Date1\"], \"dd/MM/yyyy\").cast(DateType()))\n",
    "df1 = df1.withColumn(\"Date2\", to_date(df1[\"Date2\"], \"dd/MM/yyyy\").cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Level: integer (nullable = true)\n",
      " |-- Date1: date (nullable = true)\n",
      " |-- Date2: date (nullable = true)\n",
      " |-- CN01: integer (nullable = true)\n",
      " |-- CN02: integer (nullable = true)\n",
      " |-- CN03: integer (nullable = true)\n",
      " |-- CN04: integer (nullable = true)\n",
      " |-- CN05: integer (nullable = true)\n",
      " |-- CN06: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo ficheiro com IDs 501 - 600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = (spark.read\n",
    "    .option(\"sep\", \";\")\n",
    "    .option(\"header\", \"True\")\n",
    "    .option(\"inferSchema\", \"True\")\n",
    "    .csv('/home/mcanudo/Documents/NOVA/ABD/exame/Midterm_Test_Data_25.csv')\n",
    "    )\n",
    "\n",
    "df2 = df2.withColumn(\"Date\", to_date(df2[\"Date\"], \"dd/MM/yyyy\").cast(DateType()))\n",
    "df2 = df2.withColumn(\"Date1\", to_date(df2[\"Date1\"], \"dd/MM/yyyy\").cast(DateType()))\n",
    "df2 = df2.withColumn(\"Date2\", to_date(df2[\"Date2\"], \"dd/MM/yyyy\").cast(DateType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Level: integer (nullable = true)\n",
      " |-- Date1: date (nullable = true)\n",
      " |-- Date2: date (nullable = true)\n",
      " |-- CN01: integer (nullable = true)\n",
      " |-- CN02: integer (nullable = true)\n",
      " |-- CN03: integer (nullable = true)\n",
      " |-- CN04: integer (nullable = true)\n",
      " |-- CN05: integer (nullable = true)\n",
      " |-- CN06: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terceiro ficheiro com a coluna \"Valid\" para fazer join pelo ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = (spark.read\n",
    "    .option(\"sep\", \";\")\n",
    "    .option(\"header\", \"True\")\n",
    "    .option(\"inferSchema\", \"True\")\n",
    "    .csv('/home/mcanudo/Documents/NOVA/ABD/exame/Midterm_Test_Data_24_Id_Valid.csv')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Valid: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_valid.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "| Id|      Date|Region| Color|Level|     Date1|     Date2|CN01|CN02|CN03|CN04|CN05|CN06|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "|  1|2020-01-01| South|Purple|    1|2014-12-31|2020-08-11| 111| 195| 101| 102| 136| 173|\n",
      "|  2|2020-01-02|  East|  Pink|    2|2010-04-07|2023-01-22| 171| 151| 100| 195| 166| 183|\n",
      "|  3|2020-01-03| South|   Gay|    3|2001-05-22|2021-04-08| 140| 104| 121| 127| 193| 119|\n",
      "|  4|2020-01-04| North|   Gay|    1|2021-07-24|2022-07-26| 134| 129| 158| 199| 186| 171|\n",
      "|  5|2020-01-05|  East|Orange|    1|2017-02-28|2024-01-01| 134| 171| 161| 128| 118| 139|\n",
      "|  6|2020-01-06|  East|   Gay|    3|2014-02-16|2022-04-13| 108| 111| 165| 151| 177| 144|\n",
      "|  7|2020-01-07|  West|  Blue|    2|2010-10-19|2020-02-02| 181| 156| 140| 102| 136| 170|\n",
      "|  8|2020-01-08| South|Orange|    2|2022-07-06|2021-08-18| 190| 119| 171| 141| 190| 178|\n",
      "|  9|2020-01-09|  West|Purple|    2|2018-03-03|2020-06-24| 153| 113| 176| 102| 127| 176|\n",
      "| 10|2020-01-10|  East|   Red|    3|2015-03-21|2021-03-10| 112| 141| 123| 159| 153| 123|\n",
      "| 11|2020-01-11| North|  Pink|    3|2019-08-26|2020-09-21| 131| 163| 112| 131| 122| 135|\n",
      "| 12|2020-01-12| South|Purple|    3|2005-11-01|2021-07-07| 166| 100| 140| 115| 166| 146|\n",
      "| 13|2020-01-13| North| Black|    2|2003-06-06|2023-09-26| 152| 106| 195| 129| 198| 183|\n",
      "| 14|2020-01-14| North|Purple|    1|2007-07-05|2022-07-19| 183| 116| 179| 154| 199| 169|\n",
      "| 15|2020-01-15|  East|  Blue|    2|2006-05-19|2020-05-22| 158| 165| 171| 136| 176| 181|\n",
      "| 16|2020-01-16| North|  Pink|    2|2000-11-07|2024-05-27| 161| 162| 161| 141| 187| 159|\n",
      "| 17|2020-01-17| North| White|    3|2023-02-15|2024-12-23| 131| 181| 188| 111| 171| 171|\n",
      "| 18|2020-01-18| North| White|    2|2014-06-02|2023-12-11| 162| 183| 168| 105| 168| 120|\n",
      "| 19|2020-01-19|  East|Yellow|    3|2003-01-21|2022-07-08| 177| 122| 117| 169| 120| 142|\n",
      "| 20|2020-01-20| North|Purple|    1|2023-06-18|2023-01-29| 119| 144| 198| 175| 109| 180|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "| Id|      Date|Region| Color|Level|     Date1|     Date2|CN01|CN02|CN03|CN04|CN05|CN06|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "|501|2025-01-02|  East|Orange|    1|2006-11-24|2021-08-22| 159| 175| 139| 146| 130| 145|\n",
      "|502|2025-01-03|  East|Yellow|    2|2011-05-20|2021-06-01| 118| 100| 188| 105| 167| 110|\n",
      "|503|2025-01-04|  East|Yellow|    3|2010-11-05|2020-10-11| 160| 155| 120| 146| 177| 165|\n",
      "|504|2025-01-05| North|Purple|    1|2009-11-07|2020-03-20| 105| 172| 172| 100| 184| 141|\n",
      "|505|2025-01-06| South|  Pink|    1|2013-12-01|2023-02-15| 137| 176| 165| 197| 162| 193|\n",
      "|506|2025-01-07|  East|  Blue|    2|2023-05-23|2021-10-01| 117| 168| 106| 124| 116| 184|\n",
      "|507|2025-01-08|  West|Orange|    2|2013-06-14|2020-01-12| 164| 147| 160| 196| 115| 136|\n",
      "|508|2025-01-09|  East|Orange|    3|2002-07-22|2021-07-24| 157| 180| 105| 132| 161| 162|\n",
      "|509|2025-01-10|  East| White|    2|2006-10-21|2023-05-09| 164| 134| 119| 100| 145| 133|\n",
      "|510|2025-01-11|  West|  Pink|    1|2016-11-12|2021-04-30| 182| 171| 133| 102| 186| 152|\n",
      "|511|2025-01-12| South|  Pink|    1|2011-08-21|2022-08-19| 165| 180| 168| 148| 194| 173|\n",
      "|512|2025-01-13| South|  Blue|    2|2018-01-16|2021-04-17| 168| 117| 123| 196| 138| 139|\n",
      "|513|2025-01-14| South|  Blue|    3|2003-10-08|2024-02-09| 165| 185| 114| 130| 157| 177|\n",
      "|514|2025-01-15|  East|  Blue|    2|2012-07-10|2022-03-22| 136| 173| 192| 137| 191| 135|\n",
      "|515|2025-01-16|  East|Yellow|    1|2004-01-06|2024-12-11| 174| 161| 157| 184| 137| 102|\n",
      "|516|2025-01-17| South| Black|    3|2009-05-27|2020-09-23| 161| 156| 155| 113| 143| 191|\n",
      "|517|2025-01-18|  West|   Gay|    2|2008-03-24|2023-11-22| 193| 182| 157| 181| 100| 188|\n",
      "|518|2025-01-19| South|  Blue|    1|2021-01-07|2020-03-09| 179| 175| 118| 110| 144| 150|\n",
      "|519|2025-01-20| North|  Blue|    3|2007-09-12|2021-11-13| 133| 186| 187| 125| 114| 193|\n",
      "|520|2025-01-21| North|  Blue|    2|2017-09-30|2021-06-22| 175| 121| 159| 131| 116| 165|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| Id|Valid|\n",
      "+---+-----+\n",
      "|  1|  yes|\n",
      "|  2|   no|\n",
      "|  3|  yes|\n",
      "|  4|   no|\n",
      "|  5|  yes|\n",
      "|  6|  yes|\n",
      "|  7|  yes|\n",
      "|  8|  yes|\n",
      "|  9|  yes|\n",
      "| 10|   no|\n",
      "| 11|  yes|\n",
      "| 12|   no|\n",
      "| 13|   no|\n",
      "| 14|   no|\n",
      "| 15|  yes|\n",
      "| 16|  yes|\n",
      "| 17|   no|\n",
      "| 18|  yes|\n",
      "| 19|   no|\n",
      "| 20|   no|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_valid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar as df1 e df2 -> df_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_int = df1.union(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Level: integer (nullable = true)\n",
      " |-- Date1: date (nullable = true)\n",
      " |-- Date2: date (nullable = true)\n",
      " |-- CN01: integer (nullable = true)\n",
      " |-- CN02: integer (nullable = true)\n",
      " |-- CN03: integer (nullable = true)\n",
      " |-- CN04: integer (nullable = true)\n",
      " |-- CN05: integer (nullable = true)\n",
      " |-- CN06: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_int.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "| Id|      Date|Region| Color|Level|     Date1|     Date2|CN01|CN02|CN03|CN04|CN05|CN06|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "|  1|2020-01-01| South|Purple|    1|2014-12-31|2020-08-11| 111| 195| 101| 102| 136| 173|\n",
      "|  2|2020-01-02|  East|  Pink|    2|2010-04-07|2023-01-22| 171| 151| 100| 195| 166| 183|\n",
      "|  3|2020-01-03| South|   Gay|    3|2001-05-22|2021-04-08| 140| 104| 121| 127| 193| 119|\n",
      "|  4|2020-01-04| North|   Gay|    1|2021-07-24|2022-07-26| 134| 129| 158| 199| 186| 171|\n",
      "|  5|2020-01-05|  East|Orange|    1|2017-02-28|2024-01-01| 134| 171| 161| 128| 118| 139|\n",
      "|  6|2020-01-06|  East|   Gay|    3|2014-02-16|2022-04-13| 108| 111| 165| 151| 177| 144|\n",
      "|  7|2020-01-07|  West|  Blue|    2|2010-10-19|2020-02-02| 181| 156| 140| 102| 136| 170|\n",
      "|  8|2020-01-08| South|Orange|    2|2022-07-06|2021-08-18| 190| 119| 171| 141| 190| 178|\n",
      "|  9|2020-01-09|  West|Purple|    2|2018-03-03|2020-06-24| 153| 113| 176| 102| 127| 176|\n",
      "| 10|2020-01-10|  East|   Red|    3|2015-03-21|2021-03-10| 112| 141| 123| 159| 153| 123|\n",
      "| 11|2020-01-11| North|  Pink|    3|2019-08-26|2020-09-21| 131| 163| 112| 131| 122| 135|\n",
      "| 12|2020-01-12| South|Purple|    3|2005-11-01|2021-07-07| 166| 100| 140| 115| 166| 146|\n",
      "| 13|2020-01-13| North| Black|    2|2003-06-06|2023-09-26| 152| 106| 195| 129| 198| 183|\n",
      "| 14|2020-01-14| North|Purple|    1|2007-07-05|2022-07-19| 183| 116| 179| 154| 199| 169|\n",
      "| 15|2020-01-15|  East|  Blue|    2|2006-05-19|2020-05-22| 158| 165| 171| 136| 176| 181|\n",
      "| 16|2020-01-16| North|  Pink|    2|2000-11-07|2024-05-27| 161| 162| 161| 141| 187| 159|\n",
      "| 17|2020-01-17| North| White|    3|2023-02-15|2024-12-23| 131| 181| 188| 111| 171| 171|\n",
      "| 18|2020-01-18| North| White|    2|2014-06-02|2023-12-11| 162| 183| 168| 105| 168| 120|\n",
      "| 19|2020-01-19|  East|Yellow|    3|2003-01-21|2022-07-08| 177| 122| 117| 169| 120| 142|\n",
      "| 20|2020-01-20| North|Purple|    1|2023-06-18|2023-01-29| 119| 144| 198| 175| 109| 180|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_int.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazer Join da df_int com a df_valid -> dffinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dffinal = df_int.join(df_valid, on='Id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+-----+\n",
      "| Id|      Date|Region| Color|Level|     Date1|     Date2|CN01|CN02|CN03|CN04|CN05|CN06|Valid|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+-----+\n",
      "|  1|2020-01-01| South|Purple|    1|2014-12-31|2020-08-11| 111| 195| 101| 102| 136| 173|  yes|\n",
      "|  2|2020-01-02|  East|  Pink|    2|2010-04-07|2023-01-22| 171| 151| 100| 195| 166| 183|   no|\n",
      "|  3|2020-01-03| South|   Gay|    3|2001-05-22|2021-04-08| 140| 104| 121| 127| 193| 119|  yes|\n",
      "|  4|2020-01-04| North|   Gay|    1|2021-07-24|2022-07-26| 134| 129| 158| 199| 186| 171|   no|\n",
      "|  5|2020-01-05|  East|Orange|    1|2017-02-28|2024-01-01| 134| 171| 161| 128| 118| 139|  yes|\n",
      "|  6|2020-01-06|  East|   Gay|    3|2014-02-16|2022-04-13| 108| 111| 165| 151| 177| 144|  yes|\n",
      "|  7|2020-01-07|  West|  Blue|    2|2010-10-19|2020-02-02| 181| 156| 140| 102| 136| 170|  yes|\n",
      "|  8|2020-01-08| South|Orange|    2|2022-07-06|2021-08-18| 190| 119| 171| 141| 190| 178|  yes|\n",
      "|  9|2020-01-09|  West|Purple|    2|2018-03-03|2020-06-24| 153| 113| 176| 102| 127| 176|  yes|\n",
      "| 10|2020-01-10|  East|   Red|    3|2015-03-21|2021-03-10| 112| 141| 123| 159| 153| 123|   no|\n",
      "| 11|2020-01-11| North|  Pink|    3|2019-08-26|2020-09-21| 131| 163| 112| 131| 122| 135|  yes|\n",
      "| 12|2020-01-12| South|Purple|    3|2005-11-01|2021-07-07| 166| 100| 140| 115| 166| 146|   no|\n",
      "| 13|2020-01-13| North| Black|    2|2003-06-06|2023-09-26| 152| 106| 195| 129| 198| 183|   no|\n",
      "| 14|2020-01-14| North|Purple|    1|2007-07-05|2022-07-19| 183| 116| 179| 154| 199| 169|   no|\n",
      "| 15|2020-01-15|  East|  Blue|    2|2006-05-19|2020-05-22| 158| 165| 171| 136| 176| 181|  yes|\n",
      "| 16|2020-01-16| North|  Pink|    2|2000-11-07|2024-05-27| 161| 162| 161| 141| 187| 159|  yes|\n",
      "| 17|2020-01-17| North| White|    3|2023-02-15|2024-12-23| 131| 181| 188| 111| 171| 171|   no|\n",
      "| 18|2020-01-18| North| White|    2|2014-06-02|2023-12-11| 162| 183| 168| 105| 168| 120|  yes|\n",
      "| 19|2020-01-19|  East|Yellow|    3|2003-01-21|2022-07-08| 177| 122| 117| 169| 120| 142|   no|\n",
      "| 20|2020-01-20| North|Purple|    1|2023-06-18|2023-01-29| 119| 144| 198| 175| 109| 180|   no|\n",
      "+---+----------+------+------+-----+----------+----------+----+----+----+----+----+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dffinal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 2) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|Valid|count|\n",
      "+-----+-----+\n",
      "|   no|  256|\n",
      "|  yes|  244|\n",
      "| NULL|  100|\n",
      "+-----+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dffinal.groupby(\"Valid\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
